# 1.基本配置

## 1.1 网络配置

```shell
vi /etc/sysconfig/network-scripts/ifcfg-ens33
```

文件中主要配置内容为：

```txt
BOOTPROTO=static
ONBOOT=yes
IPADDR=192.168.255.132
NETMASK=255.255.255.0
GATEWAY=192.168.255.130
DNS1=199.29.29.29
```

如果在vmare下配置，需要查看网关。

![image-20200116173206044](F:\learning大数据框架学习images\image-20200116173206044.png)



服务重启

```shell
systemctl restart network.service
ifconfig
```



## 1.2 主机名配置

```shell
vi /etc/hosts
```

```txt
192.168.133.3 hadoop-master
192.168.133.4 hadoop-slave1
192.168.133.5 hadoop-slave2
```

## 1.3 关闭防火墙

```shell
systemctl stop firewalld.service
```



## 1.4  ssh登录配置

```shell
# 安装 ssh
yum install openssl openssh-server

# 进入用户目录
cd ~

# 生成密钥（对三台机器均执行过该操作）
ssh-keygen -t rsa
回车
回车
回车

# 进入文件夹
cd .ssh
# 登录本地 输入密码
ssh localhost
# 授权本地无密码登录 
cat id_rsa.pub >> authorized_keys
# 授权 hadoop-slave1 无密码登录 
ssh hadoop-slave1 cat ~/.ssh/id_rsa.pub >> authorized_keys
# 授权 hadoop-slave2 无密码登录 
ssh hadoop-slave2 cat ~/.ssh/id_rsa.pub >> authorized_keys
# 修改权限(不修改也没出错)
chmod 600 authorized_keys
# 传输文件 输入密码
scp authorized_keys hadoop-slave1:/root/.ssh/
# 传输文件 输入密码
scp authorized_keys hadoop-slave2:/root/.ssh/

# 无需密码输入
ssh hadoop-master
# 无需密码输入
ssh hadoop-slave1
# 无需密码输入
ssh hadoop-slave2
```



#### 1.5 版本查询

```shell
# 操作系统查询
cat /proc/version
```











