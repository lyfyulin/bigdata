

pom.xml 文件依赖

```xml
<dependency>
    <groupId>org.apache.flink</groupId>
    <artifactId>flink-connector-kafka-0.11_2.11</artifactId>
    <version>1.7.0</version>
</dependency>
```



```scala
package com.lvqi.apitest


import java.util.Properties
import org.apache.flink.api.common.serialization.SimpleStringSchema
import org.apache.flink.api.scala._
import org.apache.flink.streaming.api.scala.StreamExecutionEnvironment
import org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumer011

case class SensorReading( id: String, timestamp: Long, tempreture: Double )

object SourceTest {
  def main(args: Array[String]): Unit = {
    val env = StreamExecutionEnvironment.getExecutionEnvironment
    // 1.从自定义的集合中读取数据
    val stream1 = env.fromCollection( List(
      SensorReading("sensor_1", 15433322, 35.724643),
      SensorReading("sensor_2", 15532322, 22.224652),
      SensorReading("sensor_3", 15432322, 13.322468),
      SensorReading("sensor_4", 18463322, 45.524697)
    ) )

    // 2.从文件读取
    val stream2  = env.readTextFile("F:\\code\\springboot\\wordcount\\src\\main\\resources\\sensor.txt")

    // 3.从socket读取，一般测试时候用  参见 com.lvqi.wc.StreamWordCount 类


    // 4.从kafka中读取数据
    val properties = new Properties()
    properties.setProperty("bootstrap.servers", "192.168.133.3:9092")
    properties.setProperty("group.id", "consumer-group")
    properties.setProperty("key.deserialize", "org.apache.kafka.common.serialization.StringDeserializer")
    properties.setProperty("value.deserialize", "org.apache.kafka.common.serialization.StringDeserializer")
    properties.setProperty("auto.offset.reset", "latest")
    val stream3 = env.addSource(new FlinkKafkaConsumer011[String]("sensor", new SimpleStringSchema(), properties))

    // 输出
//    stream1.setParallelism(1).print("stream1")
//    stream2.setParallelism(1).print("stream2")
    stream3.setParallelism(1).print("stream3")
    // 自己在文件中随便定义一些数字
    env.fromElements( 1, 2, 3, "str" ).print("stream3")


    env.execute("source test")

  }
}

```



```shell

kafka-console-producer.sh --broker-list 192.168.133.3:9092 --topic sensor



```



```txt
sensor_1, 1543141242, 35.1253252352
sensor_2,1222222242,35.1222222222
```















